{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fitting Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate some random numbers with values between -0.5 and 0.5, which we'll call \"noise\"\n",
    "noise = (np.random.rand(21)-0.5)\n",
    "noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot simple relationship y=2x with this noise added\n",
    "x = np.arange(21)\n",
    "data=2*x+noise\n",
    "model=2*x\n",
    "plt.plot(x,data, 'bo')\n",
    "plt.plot(x,model,'r--')\n",
    "plt.xlim(0,20)\n",
    "plt.xlabel(\"independent variable\")\n",
    "plt.ylabel(\"dependent variable\")\n",
    "plt.title(\"tight scatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make noisier noise (between -5 and 5)\n",
    "noise2 = (np.random.rand(21)-0.5)*10\n",
    "noise2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = 2*x+noise2\n",
    "plt.plot(x,data2, 'go')\n",
    "plt.plot(x,model, 'y--')\n",
    "plt.xlabel(\"independent variable\")\n",
    "plt.ylabel(\"dependent variable\")\n",
    "plt.title(\"larger scatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Residuals as metric for quality of fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = data2-model\n",
    "plt.plot(x, residuals, 'rx')\n",
    "plt.plot([0,20],[0,0],'--')\n",
    "plt.ylim(-5,5)\n",
    "plt.xlim(0,20)\n",
    "plt.xlabel('independent variable')\n",
    "plt.ylabel('data - model')\n",
    "plt.title('residual plot')\n",
    "plt.savefig('residuals.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use quantitative metric for quality of fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#squaring and square rooting gives us only positive distances \n",
    "residuals_pos = np.sqrt((residuals)**2)\n",
    "residuals_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#then add them all up to get a total measure of the difference\n",
    "total_error = sum(residuals_pos)\n",
    "total_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is usually called \"least-squares\" fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now, let's assume that I have only the data and no knowledge of the underlying model relationship\n",
    "plt.plot(x,data2, 'go')\n",
    "plt.xlabel(\"independent variable\")\n",
    "plt.ylabel(\"dependent variable\")\n",
    "plt.title(\"no fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I might first want to know something about the correlation value R for these two variables\n",
    "#there are lots of ways to do this in python. here's one\n",
    "from scipy.stats.stats import pearsonr\n",
    "#the output is the correlation coefficient R and the \"p value\", a measure of significance that we'll talk about later\n",
    "pearsonr(x,data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this sum of squares metric might also allow me to judge the quality of one model relative to another. For example:\n",
    "model2 = 2.1*x-1\n",
    "plt.plot(x,data2, 'go')\n",
    "plt.plot(x,model)\n",
    "plt.plot(x,model2,'r--')\n",
    "plt.xlabel(\"independent variable\")\n",
    "plt.ylabel(\"dependent variable\")\n",
    "plt.title(\"potential fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#they both look like reasonable matches to the data, so how do I know which one matches better?\n",
    "\n",
    "error1 = sum(np.sqrt((model-data2)**2))\n",
    "error2 = sum(np.sqrt((model2-data2)**2))\n",
    "print(\"sum of squares for model 1 \\(true\\) is \", error1)\n",
    "print(\"sum of squares for model 2 is \",error2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if you execute all these cells multiple times, not infrequently the quality of fit metric for the alternate model will be better than the \"true\" model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curve Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course there are more sophisticated ways to choose a model besides simple trial and error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python has lots of built-in functionalities for this kind of thing. let's look at a few\n",
    "#to start, let's use scipy's stats module's linregress function to find a best linear fit\n",
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_model = linregress(x, data2)\n",
    "print(lin_model)\n",
    "print(type(lin_model))\n",
    "lin_model[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's try a more general model fitting function\n",
    "import scipy.optimize as optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to use it, you have to define a functional form for the fit line BUT NOT THE SPECIFIC VALUES\n",
    "\n",
    "#for linear (straight line) fits this could take two forms\n",
    "\n",
    "#line without an intercept (intercept zero)\n",
    "def slopefunc(x,sl):\n",
    "    return sl*x\n",
    "\n",
    "#line with an intercept\n",
    "def slopeintfunc(x,sl,incpt):\n",
    "    return sl*x+incpt\n",
    "\n",
    "#we could continue this to functions of arbitraty order\n",
    "#for example, quadratic:\n",
    "\n",
    "def quadfunc(x,a,b,c):\n",
    "    return a+b*x+c*x*x\n",
    "\n",
    "def mysin(x):\n",
    "    return np.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#then use curve_fit\n",
    "fit = optimization.curve_fit(slopeintfunc,x,data2)\n",
    "#fit = optimization.curve_fit(mysin,x,data2)\n",
    "\n",
    "#the zeroth element then contains the optimal parameters for the functional parameters (in this case sl, incpt)\n",
    "#the output of the function is a python data type called a tuple, which we'll learn about later\n",
    "fit[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and the next element contains what's called the covariance matrix, which can also be quite useful\n",
    "fit[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's plot it over the data now\n",
    "plt.plot(x,data2, 'go')\n",
    "plt.plot(x, slopeintfunc(x,fit[0][0],fit[0][1]))\n",
    "plt.xlabel(\"independent variable\")\n",
    "plt.ylabel(\"dependent variable\")\n",
    "plt.title(\"least squares fit\")\n",
    "plt.savefig('leastsquaresfit.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since we can define functions to arbitrary dimensions, this can get a bit out of control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tenparamfunc(x,a,b,c,d,e,f,g,h,i,j):\n",
    "    return a+b*x+c*x**2+d*x**3+e*x**4+f*x**5+g*x**6+h*x**7+i*x**8+j*x**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit2 = optimization.curve_fit(tenparamfunc,x,data2)\n",
    "fit2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,data2, 'go')\n",
    "c = fit2[0]\n",
    "plt.plot(x, tenparamfunc(x,c[0],c[1],c[2],c[3],c[4],c[5],c[6],c[7],c[8],c[9]))\n",
    "plt.xlabel(\"independent variable\")\n",
    "plt.ylabel(\"dependent variable\")\n",
    "plt.title(\"fit for function with ten parameters\")\n",
    "plt.savefig('overfitting.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General rule of thumb\n",
    "\n",
    "Number of parameters in your model should be <<< number of data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting with error bars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often we know enough about how our measurements are taken that we can assign \"error bars\" or \"uncertainties\" to our measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equal errors (homoschedastic)\n",
    "errors_uniform = np.ones(21)\n",
    "\n",
    "#errors that vary (heteroschedastic)\n",
    "errors_poisson = np.sqrt(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize this\n",
    "plt.errorbar(x,data2,yerr=errors_uniform, fmt='go')\n",
    "plt.xlim(0,20)\n",
    "plt.xlabel(\"independent variable\")\n",
    "plt.ylabel(\"dependent variable\")\n",
    "plt.title(\"homoskedastic error bars\")\n",
    "plt.savefig('homoskedastic_errors.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(x,data2,yerr=errors_uniform, fmt='go')\n",
    "plt.xlim(0,20)\n",
    "plt.plot(x, slopeintfunc(x,fit[0][0],fit[0][1]))\n",
    "plt.xlabel(\"independent variable\")\n",
    "plt.ylabel(\"dependent variable\")\n",
    "plt.title(\"underestimated error bars (or bad model)\")\n",
    "plt.savefig('underestimated_errors.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(x,data2,yerr=errors_uniform*3, fmt='go')\n",
    "plt.xlim(-1,21)\n",
    "plt.plot(x, slopeintfunc(x,fit[0][0],fit[0][1]))\n",
    "plt.xlabel(\"independent variable\")\n",
    "plt.ylabel(\"dependent variable\")\n",
    "plt.title(\"error bars consistent with model\")\n",
    "plt.savefig('good_errors.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(x,data2,yerr=errors_poisson, fmt='go')\n",
    "plt.xlim(-1,21)\n",
    "plt.xlabel(\"independent variable\")\n",
    "plt.ylabel(\"dependent variable\")\n",
    "plt.title(\"heteroskedastic error bars\")\n",
    "plt.savefig('heteroskedastic_errors.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted Least Squares\n",
    "\n",
    "If we want to take the uncertainty in each of our data points into consideration in calculating goodness of fit, we can extend this to assigning \"weights\" to each data point. \n",
    "\n",
    "Since larger error bars indicate greater uncertainty, these data points should be assigned less weight than other data points with smaller error bars. \n",
    "\n",
    "A weight is just like a coefficient in front of the (data-model)$^2$ calculation typical to least squares. More formally:\n",
    "\n",
    "$$ Q = \\sum_{i=1}^nw_i[y_i-f(x_i,\\beta)]^2$$\n",
    "\n",
    "Where $x_i$ is the independent variable, $y_i$ are the observed values, $f(x_i,\\beta)$ is the model with some set of parameters $\\beta$ and $w_i$ are the weights for each datapoint\n",
    "\n",
    "A common weight is the reciprocal of the error value squared, or $\\frac{1}{\\sigma^2}$. Sigma here is the value of the error bar and is not to be confused with a standard deviation, though standard deviation values are often assigned as errors. \n",
    "\n",
    "Let's do this for our example of heteroschedastic error bars above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsq_weighted=sum(1/errors_poisson**2*(data2-model)**2)\n",
    "lsq_weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops what happened? Well, the model value at x=0 is 0 in this case, and the errors are too, so our 1/errors_poissson statement becomes problematic because we can't divide by zero. \n",
    "\n",
    "We can fix this by removing the datapoint from consideration (indeed it's rare that we measure something to be zero anyway, so it was a bit contrived to begin with). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3=np.arange(20)+1\n",
    "model3=2*x3\n",
    "noise3 = (np.random.rand(20)-0.5)*10\n",
    "data3= 2*x3+noise3 \n",
    "errors_poisson3 = np.sqrt(data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsq_weighted=sum(1/errors_poisson3**2*(data3-model3)**2)\n",
    "lsq_weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can build in the uncertainties/weights when we do the least squares fit to the data. As before, the function will minimize the least squares sum to find the best fit, but this time the version with the weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_weighted = optimization.curve_fit(slopeintfunc,x3,data3, sigma=errors_poisson3)\n",
    "fit_unweighted = optimization.curve_fit(slopeintfunc,x3,data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(x3,data3,yerr=errors_poisson3, fmt='go')\n",
    "plt.xlim(0,21)\n",
    "plt.ylim(-5,50)\n",
    "plt.plot(x3, slopeintfunc(x3,fit_weighted[0][0],fit_weighted[0][1]), label='weighted')\n",
    "plt.plot(x3, slopeintfunc(x3,fit_unweighted[0][0],fit_unweighted[0][1]), 'r--', label='unweighted')\n",
    "plt.legend(loc='lower right',)\n",
    "plt.xlabel(\"independent variable\")\n",
    "plt.ylabel(\"dependent variable\")\n",
    "plt.title(\"weighted vs. unweighted fits\")\n",
    "plt.savefig('weighted_v_not.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
